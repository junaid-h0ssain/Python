{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T14:53:25.582849Z",
     "iopub.status.busy": "2025-12-04T14:53:25.582194Z",
     "iopub.status.idle": "2025-12-04T14:53:25.596564Z",
     "shell.execute_reply": "2025-12-04T14:53:25.595805Z",
     "shell.execute_reply.started": "2025-12-04T14:53:25.582825Z"
    },
    "id": "kJLG7VcnmRTt",
    "outputId": "b3519b06-5eee-4c0e-943c-e65e192ddf83",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Enable mixed precision for faster training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T14:53:29.028598Z",
     "iopub.status.busy": "2025-12-04T14:53:29.028058Z",
     "iopub.status.idle": "2025-12-04T14:53:29.333530Z",
     "shell.execute_reply": "2025-12-04T14:53:29.332860Z",
     "shell.execute_reply.started": "2025-12-04T14:53:29.028571Z"
    },
    "id": "RCmICxH4mjgx",
    "outputId": "48c4d947-97a2-4ede-e502-ba009307eac0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/new-plant-diseases-dataset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T14:53:31.883596Z",
     "iopub.status.busy": "2025-12-04T14:53:31.883075Z",
     "iopub.status.idle": "2025-12-04T14:53:31.887431Z",
     "shell.execute_reply": "2025-12-04T14:53:31.886611Z",
     "shell.execute_reply.started": "2025-12-04T14:53:31.883569Z"
    },
    "id": "Y-DmJZw5mRTu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "# For Kaggle kernel:\n",
    "train = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
    "valid = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
    "\n",
    "# train = \"C:\\\\Users\\\\junu\\\\.cache\\\\kagglehub\\\\datasets\\\\vipoooool\\\\new-plant-diseases-dataset\\\\versions\\\\2\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\"\n",
    "# valid = \"C:\\\\Users\\\\junu\\\\.cache\\\\kagglehub\\\\datasets\\\\vipoooool\\\\new-plant-diseases-dataset\\\\versions\\\\2\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T14:53:35.082595Z",
     "iopub.status.busy": "2025-12-04T14:53:35.081990Z",
     "iopub.status.idle": "2025-12-04T14:53:35.086740Z",
     "shell.execute_reply": "2025-12-04T14:53:35.085902Z",
     "shell.execute_reply.started": "2025-12-04T14:53:35.082564Z"
    },
    "id": "nKbJD82tmRTv",
    "outputId": "93415f07-8c8f-4e44-e8a7-75046ed4b7ec",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (224, 224)\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "image_size = (224, 224)  \n",
    "batch_size = 32          \n",
    "\n",
    "print(f\"Image size: {image_size}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T16:18:57.822138Z",
     "iopub.status.busy": "2025-12-04T16:18:57.821339Z",
     "iopub.status.idle": "2025-12-04T16:19:40.359974Z",
     "shell.execute_reply": "2025-12-04T16:19:40.359270Z",
     "shell.execute_reply.started": "2025-12-04T16:18:57.822111Z"
    },
    "id": "sy3p_eWQmRTv",
    "outputId": "b5e04546-0c83-4edc-a0ad-c16be3736d24",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Found 70295 files belonging to 38 classes.\n",
      "Found 17572 files belonging to 38 classes.\n",
      "Number of classes: 38\n",
      "\n",
      "✓ Datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create datasets WITHOUT caching\n",
    "def create_datasets():\n",
    "    \"\"\"\n",
    "    Create training and validation datasets WITHOUT caching.\n",
    "    Data will be loaded fresh from disk each epoch.\n",
    "    Uses minimal memory but slower training.\n",
    "    \"\"\"\n",
    "    # Training dataset\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train,\n",
    "        seed=123,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Validation dataset\n",
    "    val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        valid,\n",
    "        seed=123,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Save class names\n",
    "    class_names = train_dataset.class_names\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    total_batches = train_dataset.cardinality().numpy()\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(\n",
    "        buffer_size=100,\n",
    "        reshuffle_each_iteration=True\n",
    "    )\n",
    "\n",
    "    portion = 0.5\n",
    "    train_dataset = train_dataset.take(int(total_batches * portion))\n",
    "\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(1./255),\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "        tf.keras.layers.RandomZoom(0.2),\n",
    "        tf.keras.layers.RandomContrast(0.2),\n",
    "    ])\n",
    "\n",
    "    normalization = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda x, y: (data_augmentation(x, training=True), y),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_dataset = val_dataset.map(\n",
    "        lambda x, y: (normalization(x), y),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset, class_names, num_classes\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset, val_dataset, class_names, num_classes = create_datasets()\n",
    "print(\"\\n Datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T16:22:34.563030Z",
     "iopub.status.busy": "2025-12-04T16:22:34.562267Z",
     "iopub.status.idle": "2025-12-04T16:22:34.569376Z",
     "shell.execute_reply": "2025-12-04T16:22:34.568568Z",
     "shell.execute_reply.started": "2025-12-04T16:22:34.563004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n"
     ]
    }
   ],
   "source": [
    "def create_model(base_model_class, model_name, num_classes):\n",
    "\n",
    "    base_model = base_model_class(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=image_size + (3,)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        jit_compile=True\n",
    "    )\n",
    "\n",
    "    return model, base_model\n",
    "print(\"Model Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T16:22:37.018755Z",
     "iopub.status.busy": "2025-12-04T16:22:37.018073Z",
     "iopub.status.idle": "2025-12-04T16:22:37.023519Z",
     "shell.execute_reply": "2025-12-04T16:22:37.022662Z",
     "shell.execute_reply.started": "2025-12-04T16:22:37.018731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tune model Created\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_model(model, base_model, num_layers_to_unfreeze=20):\n",
    "   \n",
    "    base_model.trainable = True\n",
    "\n",
    "    for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Fine Tune model Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T16:22:55.455605Z",
     "iopub.status.busy": "2025-12-04T16:22:55.454923Z",
     "iopub.status.idle": "2025-12-04T16:22:55.460352Z",
     "shell.execute_reply": "2025-12-04T16:22:55.459635Z",
     "shell.execute_reply.started": "2025-12-04T16:22:55.455580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made Callbacks\n"
     ]
    }
   ],
   "source": [
    "def get_callbacks(model_name):\n",
    "    \"\"\"\n",
    "    Callbacks that monitor TRAINING metrics only (not validation).\n",
    "    Since we're not validating during training, we monitor 'accuracy' and 'loss' instead.\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='accuracy',  \n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode='max'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='loss',  \n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'{model_name}_best.weights.h5',\n",
    "            monitor='accuracy',  \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            verbose=1,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "print('Made Callbacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-04T16:23:03.802284Z",
     "iopub.status.busy": "2025-12-04T16:23:03.801631Z",
     "iopub.status.idle": "2025-12-04T16:23:03.813723Z",
     "shell.execute_reply": "2025-12-04T16:23:03.813109Z",
     "shell.execute_reply.started": "2025-12-04T16:23:03.802253Z"
    },
    "id": "EpKKWDDOmRTw",
    "outputId": "1c38b191-7f6c-45be-9210-c97102b02f0f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fixed helper function defined\n"
     ]
    }
   ],
   "source": [
    "def train_single_model(model_name, base_model_class):\n",
    "    \"\"\"\n",
    "    Train a model WITHOUT validation during training.\n",
    "    Validation is performed ONLY AFTER training is complete.\n",
    "    \"\"\"\n",
    "    print(f\"=\"*80)\n",
    "    print(f\"TRAINING {model_name}\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # Special preprocessing for ResNet50\n",
    "    if model_name == 'ResNet50':\n",
    "        print(f\"\\nCreating datasets with ResNet50-specific preprocessing...\")\n",
    "        from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "        \n",
    "        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            train,\n",
    "            seed=123,\n",
    "            image_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            label_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            valid,\n",
    "            seed=123,\n",
    "            image_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            label_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        total_batches = train_ds.cardinality().numpy()\n",
    "        train_ds = train_ds.shuffle(buffer_size=100, reshuffle_each_iteration=True)\n",
    "        \n",
    "        portion = 0.5\n",
    "        train_ds = train_ds.take(int(total_batches * portion))\n",
    "        \n",
    "        print(f\"Using {int(total_batches * portion)} batches for training\")\n",
    "        \n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "            tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "            tf.keras.layers.RandomRotation(0.2),\n",
    "            tf.keras.layers.RandomZoom(0.2),\n",
    "            tf.keras.layers.RandomContrast(0.2),\n",
    "        ])\n",
    "        \n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (preprocess_input(data_augmentation(x, training=True)), y),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        val_ds = val_ds.map(\n",
    "            lambda x, y: (preprocess_input(x), y),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        train_dataset_model = train_ds\n",
    "        val_dataset_model = val_ds\n",
    "    else:\n",
    "        train_dataset_model = train_dataset\n",
    "        val_dataset_model = val_dataset\n",
    "\n",
    "    print(f\"\\nCreating {model_name} model...\")\n",
    "    model, base_model = create_model(base_model_class, model_name, num_classes)\n",
    "    print(f\"✓ {model_name} model created\")\n",
    "\n",
    "    print(f\"\\n[STAGE 1] Initial training with frozen base model...\")\n",
    "    print(\"NOTE: No validation during training - validation will run after training completes\")\n",
    "    initial_epochs = 20\n",
    "\n",
    "    history_stage1 = model.fit(\n",
    "        train_dataset_model,\n",
    "        # validation_data=val_dataset_model,  # ← REMOVED\n",
    "        epochs=initial_epochs,\n",
    "        callbacks=get_callbacks(f\"{model_name}_stage1\")\n",
    "    )\n",
    "    \n",
    "    # Validate AFTER Stage 1 training\n",
    "    print(f\"\\n[VALIDATION AFTER STAGE 1]\")\n",
    "    val_loss_s1, val_acc_s1 = model.evaluate(val_dataset_model, verbose=1)\n",
    "    print(f\"Stage 1 Validation - Loss: {val_loss_s1:.4f}, Accuracy: {val_acc_s1*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\n[STAGE 2] Fine-tuning with unfrozen top layers...\")\n",
    "    print(\"NOTE: No validation during training - validation will run after training completes\")\n",
    "    model = fine_tune_model(model, base_model, num_layers_to_unfreeze=30)\n",
    "    fine_tune_epochs = 20\n",
    "    \n",
    "    history_stage2 = model.fit(\n",
    "        train_dataset_model,\n",
    "        # validation_data=val_dataset_model,  # ← REMOVED\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=get_callbacks(f\"{model_name}_stage2\")\n",
    "    )\n",
    "    \n",
    "    # Validate AFTER Stage 2 training\n",
    "    print(f\"\\n[VALIDATION AFTER STAGE 2]\")\n",
    "    val_loss_s2, val_acc_s2 = model.evaluate(val_dataset_model, verbose=1)\n",
    "    print(f\"Stage 2 Validation - Loss: {val_loss_s2:.4f}, Accuracy: {val_acc_s2*100:.2f}%\")\n",
    "\n",
    "    model.save(f\"{model_name}_plant_disease_model.h5\")\n",
    "    print(f\"\\n✓ {model_name} model saved\")\n",
    "\n",
    "    print(f\"\\nGenerating predictions for {model_name}...\")\n",
    "    y_pred = model.predict(val_dataset_model)\n",
    "\n",
    "    y_true = []\n",
    "    for image_batch, label_batch in val_dataset_model:\n",
    "        y_true.append(label_batch)\n",
    "    y_true = tf.concat(y_true, axis=0).numpy()\n",
    "\n",
    "    np.save(f\"{model_name}_y_pred.npy\", y_pred)\n",
    "    np.save(f\"{model_name}_y_true.npy\", y_true)\n",
    "    print(f\"✓ {model_name} predictions saved\")\n",
    "\n",
    "    y_pred_labels = y_pred.argmax(axis=1)\n",
    "    y_true_labels = y_true.argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred_labels == y_true_labels)\n",
    "\n",
    "    print(f\"\\n{model_name} FINAL VALIDATION ACCURACY: {accuracy*100:.2f}%\")\n",
    "\n",
    "    if accuracy >= 0.985:\n",
    "        print(f\"✓ {model_name} achieved >=98.5% accuracy!\")\n",
    "    else:\n",
    "        print(f\"✗ {model_name} did not reach 98.5% accuracy (got {accuracy*100:.2f}%)\")\n",
    "\n",
    "    del model, base_model\n",
    "    if model_name == 'ResNet50':\n",
    "        del train_ds, val_ds, train_dataset_model, val_dataset_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "print(\"Fixed helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XAHNx9OmRTw"
   },
   "source": [
    "---\n",
    "## Model Training Cells\n",
    "**Run each cell below to train that specific model. Skip any cell to exclude that model from training.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXcKwddjmRTx"
   },
   "outputs": [],
   "source": [
    "# Train VGG16\n",
    "try:\n",
    "    vgg16_accuracy = train_single_model('VGG16', VGG16)\n",
    "except Exception as e:\n",
    "    print(f\" Error training VGG16: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJQDASq7mRTy"
   },
   "outputs": [],
   "source": [
    "# Train VGG19\n",
    "try:\n",
    "    vgg19_accuracy = train_single_model('VGG19', VGG19)\n",
    "except Exception as e:\n",
    "    print(f\" Error training VGG19: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T15:26:37.428694Z",
     "iopub.status.busy": "2025-12-04T15:26:37.427977Z",
     "iopub.status.idle": "2025-12-04T15:58:25.794700Z",
     "shell.execute_reply": "2025-12-04T15:58:25.794006Z",
     "shell.execute_reply.started": "2025-12-04T15:26:37.428672Z"
    },
    "id": "aN6aaNBumRTz",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING InceptionV3\n",
      "================================================================================\n",
      "\n",
      "Creating InceptionV3 model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "✓ InceptionV3 model created\n",
      "\n",
      "[STAGE 1] Initial training with frozen base model...\n",
      "Epoch 1/15\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.2197 - loss: 3.0633\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61205, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 315ms/step - accuracy: 0.2209 - loss: 3.0571 - val_accuracy: 0.6121 - val_loss: 1.2570 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5462 - loss: 1.5186\n",
      "Epoch 2: val_accuracy improved from 0.61205 to 0.71056, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 264ms/step - accuracy: 0.5463 - loss: 1.5182 - val_accuracy: 0.7106 - val_loss: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6280 - loss: 1.2164\n",
      "Epoch 3: val_accuracy improved from 0.71056 to 0.74607, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 264ms/step - accuracy: 0.6280 - loss: 1.2163 - val_accuracy: 0.7461 - val_loss: 0.7862 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6656 - loss: 1.0418\n",
      "Epoch 4: val_accuracy improved from 0.74607 to 0.77237, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 264ms/step - accuracy: 0.6657 - loss: 1.0418 - val_accuracy: 0.7724 - val_loss: 0.6971 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6978 - loss: 0.9672\n",
      "Epoch 5: val_accuracy improved from 0.77237 to 0.79058, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 266ms/step - accuracy: 0.6978 - loss: 0.9672 - val_accuracy: 0.7906 - val_loss: 0.6477 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7093 - loss: 0.9468\n",
      "Epoch 6: val_accuracy did not improve from 0.79058\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.7093 - loss: 0.9469 - val_accuracy: 0.7824 - val_loss: 0.6653 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7196 - loss: 0.8976\n",
      "Epoch 7: val_accuracy did not improve from 0.79058\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.7196 - loss: 0.8977 - val_accuracy: 0.7845 - val_loss: 0.6615 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7295 - loss: 0.8592\n",
      "Epoch 8: val_accuracy improved from 0.79058 to 0.79735, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 264ms/step - accuracy: 0.7295 - loss: 0.8592 - val_accuracy: 0.7973 - val_loss: 0.6149 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7309 - loss: 0.8218\n",
      "Epoch 9: val_accuracy did not improve from 0.79735\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.7309 - loss: 0.8219 - val_accuracy: 0.7470 - val_loss: 0.7795 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7403 - loss: 0.8372\n",
      "Epoch 10: val_accuracy improved from 0.79735 to 0.80520, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 265ms/step - accuracy: 0.7402 - loss: 0.8372 - val_accuracy: 0.8052 - val_loss: 0.5909 - learning_rate: 0.0010\n",
      "Epoch 11/15\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7361 - loss: 0.7944\n",
      "Epoch 11: val_accuracy did not improve from 0.80520\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 260ms/step - accuracy: 0.7361 - loss: 0.7945 - val_accuracy: 0.7979 - val_loss: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 12/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7451 - loss: 0.8152\n",
      "Epoch 12: val_accuracy improved from 0.80520 to 0.81914, saving model to InceptionV3_stage1_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 267ms/step - accuracy: 0.7451 - loss: 0.8152 - val_accuracy: 0.8191 - val_loss: 0.5456 - learning_rate: 0.0010\n",
      "Epoch 13/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7579 - loss: 0.7479\n",
      "Epoch 13: val_accuracy did not improve from 0.81914\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 259ms/step - accuracy: 0.7579 - loss: 0.7479 - val_accuracy: 0.8184 - val_loss: 0.5421 - learning_rate: 0.0010\n",
      "Epoch 14/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7571 - loss: 0.7362\n",
      "Epoch 14: val_accuracy did not improve from 0.81914\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.7571 - loss: 0.7362 - val_accuracy: 0.8161 - val_loss: 0.5636 - learning_rate: 0.0010\n",
      "Epoch 15/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7529 - loss: 0.7992\n",
      "Epoch 15: val_accuracy did not improve from 0.81914\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.7529 - loss: 0.7991 - val_accuracy: 0.8107 - val_loss: 0.6184 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\n",
      "[STAGE 2] Fine-tuning with unfrozen top layers...\n",
      "Epoch 1/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7380 - loss: 0.8215\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84959, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 304ms/step - accuracy: 0.7381 - loss: 0.8213 - val_accuracy: 0.8496 - val_loss: 0.4550 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7992 - loss: 0.6091\n",
      "Epoch 2: val_accuracy improved from 0.84959 to 0.87554, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 268ms/step - accuracy: 0.7992 - loss: 0.6090 - val_accuracy: 0.8755 - val_loss: 0.3731 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8219 - loss: 0.5520\n",
      "Epoch 3: val_accuracy improved from 0.87554 to 0.88328, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 265ms/step - accuracy: 0.8219 - loss: 0.5520 - val_accuracy: 0.8833 - val_loss: 0.3550 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8358 - loss: 0.5044\n",
      "Epoch 4: val_accuracy improved from 0.88328 to 0.88675, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 266ms/step - accuracy: 0.8358 - loss: 0.5043 - val_accuracy: 0.8868 - val_loss: 0.3425 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8476 - loss: 0.4550\n",
      "Epoch 5: val_accuracy did not improve from 0.88675\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.8476 - loss: 0.4549 - val_accuracy: 0.8816 - val_loss: 0.3528 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8613 - loss: 0.4357\n",
      "Epoch 6: val_accuracy improved from 0.88675 to 0.90183, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 267ms/step - accuracy: 0.8613 - loss: 0.4357 - val_accuracy: 0.9018 - val_loss: 0.3004 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8745 - loss: 0.3885\n",
      "Epoch 7: val_accuracy improved from 0.90183 to 0.90536, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.8745 - loss: 0.3885 - val_accuracy: 0.9054 - val_loss: 0.2793 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8686 - loss: 0.3993\n",
      "Epoch 8: val_accuracy did not improve from 0.90536\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.8686 - loss: 0.3993 - val_accuracy: 0.9037 - val_loss: 0.2868 - learning_rate: 1.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8651 - loss: 0.3974\n",
      "Epoch 9: val_accuracy improved from 0.90536 to 0.91008, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 266ms/step - accuracy: 0.8651 - loss: 0.3973 - val_accuracy: 0.9101 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8897 - loss: 0.3394\n",
      "Epoch 10: val_accuracy improved from 0.91008 to 0.91515, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 267ms/step - accuracy: 0.8897 - loss: 0.3394 - val_accuracy: 0.9151 - val_loss: 0.2562 - learning_rate: 1.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8906 - loss: 0.3427\n",
      "Epoch 11: val_accuracy did not improve from 0.91515\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.8906 - loss: 0.3427 - val_accuracy: 0.9137 - val_loss: 0.2510 - learning_rate: 1.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9013 - loss: 0.3123\n",
      "Epoch 12: val_accuracy improved from 0.91515 to 0.91993, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 266ms/step - accuracy: 0.9012 - loss: 0.3123 - val_accuracy: 0.9199 - val_loss: 0.2404 - learning_rate: 1.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9018 - loss: 0.3183\n",
      "Epoch 13: val_accuracy did not improve from 0.91993\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.9018 - loss: 0.3183 - val_accuracy: 0.9179 - val_loss: 0.2414 - learning_rate: 1.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9001 - loss: 0.2971\n",
      "Epoch 14: val_accuracy did not improve from 0.91993\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.9001 - loss: 0.2971 - val_accuracy: 0.9149 - val_loss: 0.2475 - learning_rate: 1.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9053 - loss: 0.2948\n",
      "Epoch 15: val_accuracy improved from 0.91993 to 0.92061, saving model to InceptionV3_stage2_best.weights.h5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 265ms/step - accuracy: 0.9053 - loss: 0.2948 - val_accuracy: 0.9206 - val_loss: 0.2380 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ InceptionV3 model saved\n",
      "\n",
      "Generating predictions for InceptionV3...\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 49ms/step\n",
      "✓ InceptionV3 predictions saved\n",
      "\n",
      "InceptionV3 FINAL VALIDATION ACCURACY: 92.06%\n",
      "✗ InceptionV3 did not reach 98.5% accuracy (got 92.06%)\n"
     ]
    }
   ],
   "source": [
    "# Train InceptionV3\n",
    "try:\n",
    "    inceptionv3_accuracy = train_single_model('InceptionV3', InceptionV3)\n",
    "except Exception as e:\n",
    "    print(f\" Error training InceptionV3: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3p8_BeimRTz"
   },
   "outputs": [],
   "source": [
    "# Train Xception\n",
    "try:\n",
    "    xception_accuracy = train_single_model('Xception', Xception)\n",
    "except Exception as e:\n",
    "    print(f\" Error training Xception: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T16:23:37.208406Z",
     "iopub.status.busy": "2025-12-04T16:23:37.207704Z"
    },
    "id": "_m6xoV2-mRTz",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ResNet50\n",
      "\n",
      "Creating datasets with ResNet50-specific preprocessing...\n",
      "Found 70295 files belonging to 38 classes.\n",
      "Found 17572 files belonging to 38 classes.\n",
      "Using 1098 batches for training\n",
      "\n",
      "Creating ResNet50 model...\n",
      "✓ ResNet50 model created\n",
      "\n",
      "[STAGE 1] Initial training with frozen base model...\n",
      "Epoch 1/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6210 - loss: 1.3611\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91555, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 216ms/step - accuracy: 0.6211 - loss: 1.3606 - val_accuracy: 0.9155 - val_loss: 0.2477 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1097/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8687 - loss: 0.4122\n",
      "Epoch 2: val_accuracy improved from 0.91555 to 0.92562, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 206ms/step - accuracy: 0.8687 - loss: 0.4122 - val_accuracy: 0.9256 - val_loss: 0.2117 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8946 - loss: 0.3242\n",
      "Epoch 3: val_accuracy improved from 0.92562 to 0.92881, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 202ms/step - accuracy: 0.8946 - loss: 0.3242 - val_accuracy: 0.9288 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1097/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9090 - loss: 0.2775\n",
      "Epoch 4: val_accuracy improved from 0.92881 to 0.94480, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 202ms/step - accuracy: 0.9090 - loss: 0.2775 - val_accuracy: 0.9448 - val_loss: 0.1622 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9109 - loss: 0.2727\n",
      "Epoch 5: val_accuracy did not improve from 0.94480\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 203ms/step - accuracy: 0.9109 - loss: 0.2727 - val_accuracy: 0.9317 - val_loss: 0.1973 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9211 - loss: 0.2398\n",
      "Epoch 6: val_accuracy improved from 0.94480 to 0.95413, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 202ms/step - accuracy: 0.9211 - loss: 0.2398 - val_accuracy: 0.9541 - val_loss: 0.1337 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9229 - loss: 0.2406\n",
      "Epoch 7: val_accuracy did not improve from 0.95413\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 200ms/step - accuracy: 0.9229 - loss: 0.2406 - val_accuracy: 0.9360 - val_loss: 0.1972 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9287 - loss: 0.2253\n",
      "Epoch 8: val_accuracy did not improve from 0.95413\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 203ms/step - accuracy: 0.9287 - loss: 0.2253 - val_accuracy: 0.9458 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9298 - loss: 0.2086\n",
      "Epoch 9: val_accuracy improved from 0.95413 to 0.96244, saving model to ResNet50_stage1_best.weights.h5\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 200ms/step - accuracy: 0.9298 - loss: 0.2086 - val_accuracy: 0.9624 - val_loss: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9324 - loss: 0.2055\n",
      "Epoch 10: val_accuracy did not improve from 0.96244\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 202ms/step - accuracy: 0.9324 - loss: 0.2055 - val_accuracy: 0.9449 - val_loss: 0.1630 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9373 - loss: 0.1948\n",
      "Epoch 11: val_accuracy did not improve from 0.96244\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 200ms/step - accuracy: 0.9373 - loss: 0.1948 - val_accuracy: 0.9464 - val_loss: 0.1638 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m1097/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9402 - loss: 0.1785\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.96244\n",
      "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 202ms/step - accuracy: 0.9402 - loss: 0.1785 - val_accuracy: 0.9561 - val_loss: 0.1299 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m 932/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m29s\u001b[0m 180ms/step - accuracy: 0.9454 - loss: 0.1642"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resnet50_accuracy = train_single_model('ResNet50', ResNet50)\n",
    "except Exception as e:\n",
    "    print(f\" Error training ResNet50: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tk4KdR7wmRT0",
    "outputId": "d69c7713-f01e-4844-d98d-c33192a68297",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train DenseNet121\n",
    "try:\n",
    "    densenet121_accuracy = train_single_model('DenseNet121', DenseNet121)\n",
    "except Exception as e:\n",
    "    print(f\" Error training DenseNet121: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfY9K7i0mRT0"
   },
   "source": [
    "---\n",
    "## Results & Comparison\n",
    "**Run the cells below after training your models to see the comparison.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mv1RLDl2mRT0"
   },
   "outputs": [],
   "source": [
    "# Generate comparison table\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# List of all possible models\n",
    "all_models = ['VGG16', 'VGG19', 'InceptionV3', 'Xception', 'ResNet50', 'DenseNet121']\n",
    "results = []\n",
    "\n",
    "for model_name in all_models:\n",
    "    try:\n",
    "        y_pred = np.load(f\"{model_name}_y_pred.npy\")\n",
    "        y_true = np.load(f\"{model_name}_y_true.npy\")\n",
    "\n",
    "        y_pred_labels = y_pred.argmax(axis=1)\n",
    "        y_true_labels = y_true.argmax(axis=1)\n",
    "\n",
    "        accuracy = np.mean(y_pred_labels == y_true_labels)\n",
    "        precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "        recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "        f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "        top5_pred = np.argsort(y_pred, axis=1)[:, -5:]\n",
    "        top5_accuracy = np.mean([y_true_labels[i] in top5_pred[i] for i in range(len(y_true_labels))])\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy (%)': accuracy * 100,\n",
    "            'Precision (%)': precision * 100,\n",
    "            'Recall (%)': recall * 100,\n",
    "            'F1-Score (%)': f1 * 100,\n",
    "            'Top-5 Accuracy (%)': top5_accuracy * 100,\n",
    "            'Meets Target (>98.5%)': '✓' if accuracy > 0.985 else '✗'\n",
    "        })\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{model_name} was not trained (skipped)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load results for {model_name}: {str(e)}\")\n",
    "\n",
    "if len(results) > 0:\n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df = comparison_df.sort_values('Accuracy (%)', ascending=False)\n",
    "\n",
    "    print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    models_above_target = comparison_df[comparison_df['Meets Target (>98.5%)'] == '✓'].shape[0]\n",
    "    print(f\"\\nModels achieving >98.5% accuracy: {models_above_target}/{len(results)}\")\n",
    "\n",
    "    comparison_df.to_csv('model_comparison_sequential.csv', index=False)\n",
    "    print(\"\\n Comparison table saved to 'model_comparison_sequential.csv'\")\n",
    "else:\n",
    "    print(\"\\n  No models were trained. Please run at least one model training cell above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQPFtulemRT0"
   },
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if len(results) > 0:\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    colors = ['green' if x == '✓' else 'red' for x in comparison_df['Meets Target (>98.5%)']]\n",
    "    plt.barh(comparison_df['Model'], comparison_df['Accuracy (%)'], color=colors, alpha=0.7)\n",
    "    plt.axvline(x=98.5, color='blue', linestyle='--', label='Target (98.5%)')\n",
    "    plt.xlabel('Accuracy (%)')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    metrics_df = comparison_df[['Model', 'Precision (%)', 'Recall (%)', 'F1-Score (%)']].set_index('Model')\n",
    "    metrics_df.plot(kind='bar', ax=plt.gca(), width=0.8)\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.title('Model Metrics Comparison')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('model_comparison_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\" Visualization saved to 'model_comparison_visualization.png'\")\n",
    "else:\n",
    "    print(\"  No results to visualize. Train at least one model first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m72gSaybmRT1"
   },
   "outputs": [],
   "source": [
    "# Generate detailed classification reports\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "\n",
    "for model_name in all_models:\n",
    "    try:\n",
    "        y_pred = np.load(f\"{model_name}_y_pred.npy\")\n",
    "        y_true = np.load(f\"{model_name}_y_true.npy\")\n",
    "\n",
    "        y_pred_labels = y_pred.argmax(axis=1)\n",
    "        y_true_labels = y_true.argmax(axis=1)\n",
    "\n",
    "        print(f\"{model_name} - Classification Report\")\n",
    "       \n",
    "\n",
    "        report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n",
    "        print(report)\n",
    "\n",
    "        # Save report\n",
    "        with open(f\"{model_name}_classification_report.txt\", 'w') as f:\n",
    "            f.write(f\"{model_name} - Classification Report\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(report)\n",
    "\n",
    "        print(f\" Report saved to '{model_name}_classification_report.txt'\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n  {model_name} was not trained (skipped)\")\n",
    "    except Exception as e:\n",
    "        print(f\" Could not generate report for {model_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM4UZ7PNmRT1"
   },
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"FINAL SUMMARY\")\n",
    "\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(f\"\\nTotal models trained: {len(results)}\")\n",
    "    print(f\"Models achieving >98.5% accuracy: {models_above_target}\")\n",
    "    print(f\"\\nBest performing model: {comparison_df.iloc[0]['Model']}\")\n",
    "    print(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy (%)']:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n  No models were trained.\")\n",
    "\n",
    "print(\"\\nKey features implemented:\")\n",
    "print(\"   Sequential training (one model at a time)\")\n",
    "print(\"   Separate cells for each model (skip any model)\")\n",
    "print(\"   NO caching (minimal memory usage)\")\n",
    "print(\"   Memory management between models\")\n",
    "print(\"   GPU memory growth enabled\")\n",
    "print(\"   Mixed precision training\")\n",
    "print(\"   Two-stage training with fine-tuning\")\n",
    "print(\"   Enhanced data augmentation\")\n",
    "print(\"   Learning rate scheduling\")\n",
    "print(\"   Early stopping and model checkpointing\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 193494,
     "datasetId": 78313,
     "isSourceIdPinned": false,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
