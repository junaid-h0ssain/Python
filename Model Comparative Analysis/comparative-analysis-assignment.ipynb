{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":182633,"datasetId":78313,"databundleVersionId":193494,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U 'tensorflow[and-cuda]'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:07:40.924050Z","iopub.execute_input":"2025-12-02T14:07:40.924672Z","iopub.status.idle":"2025-12-02T14:08:44.626990Z","shell.execute_reply.started":"2025-12-02T14:07:40.924638Z","shell.execute_reply":"2025-12-02T14:08:44.626251Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.18.0)\nCollecting tensorflow[and-cuda]\n  Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\nRequirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\nRequirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.0)\nCollecting protobuf>=5.28.0 (from tensorflow[and-cuda])\n  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.1.0)\nRequirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.74.0)\nCollecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting keras>=3.10.0 (from tensorflow[and-cuda])\n  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.14.0)\nCollecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\nRequirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\nRequirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\nRequirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\nRequirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\nRequirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\nRequirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\nCollecting nvidia-nccl-cu12<3.0,>=2.25.1 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.10.5)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (11.3.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.0->tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\nDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, nvidia-nccl-cu12, ml_dtypes, tensorboard, keras, tensorflow\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 5.26.1\n    Uninstalling protobuf-5.26.1:\n      Successfully uninstalled protobuf-5.26.1\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: ml_dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.8.0\n    Uninstalling keras-3.8.0:\n      Successfully uninstalled keras-3.8.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.1 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.28.9 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.20.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.12.0 ml_dtypes-0.5.4 nvidia-nccl-cu12-2.28.9 protobuf-6.33.1 tensorboard-2.20.0 tensorflow-2.20.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import Required Libraries\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50, DenseNet121\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport os\nimport numpy as np\n\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:09:11.336298Z","iopub.execute_input":"2025-12-02T14:09:11.337009Z","iopub.status.idle":"2025-12-02T14:09:19.822611Z","shell.execute_reply.started":"2025-12-02T14:09:11.336977Z","shell.execute_reply":"2025-12-02T14:09:19.821981Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:09:32.910465Z","iopub.execute_input":"2025-12-02T14:09:32.911319Z","iopub.status.idle":"2025-12-02T14:09:34.491548Z","shell.execute_reply.started":"2025-12-02T14:09:32.911295Z","shell.execute_reply":"2025-12-02T14:09:34.490821Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/new-plant-diseases-dataset\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\nvalid = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:10:24.085328Z","iopub.execute_input":"2025-12-02T14:10:24.086046Z","iopub.status.idle":"2025-12-02T14:10:24.089329Z","shell.execute_reply.started":"2025-12-02T14:10:24.086020Z","shell.execute_reply":"2025-12-02T14:10:24.088693Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\n\n# Load and Preprocess Dataset\nimage_size = (128,128)\nbatch_size = 32\n\n# Training dataset with augmentation\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    train,\n    validation_split=0.2,\n    subset='training',\n    seed=123,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode='categorical',\n    shuffle=True\n)\n\n# Validation dataset (no augmentation needed)\nval_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    valid,\n    validation_split=0.2,\n    subset='validation',\n    seed=123,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\n# SAVE class_names BEFORE applying transformations\nclass_names = train_dataset.class_names\nnum_classes = len(class_names)\n\n# Data augmentation layer\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.Rescaling(1./255),\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomZoom(0.2)\n])\n\n# Apply augmentation and prefetching to training data\ntrain_dataset = train_dataset.map(\n    lambda x, y: (data_augmentation(x, training=True), y),\n    num_parallel_calls=tf.data.AUTOTUNE\n).prefetch(tf.data.AUTOTUNE)\n\n# Apply normalization and prefetching to validation data\nnormalization = tf.keras.layers.Rescaling(1./255)\nval_dataset = val_dataset.map(\n    lambda x, y: (normalization(x), y),\n    num_parallel_calls=tf.data.AUTOTUNE\n).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:22:32.362618Z","iopub.execute_input":"2025-12-02T14:22:32.363407Z","iopub.status.idle":"2025-12-02T14:22:38.185717Z","shell.execute_reply.started":"2025-12-02T14:22:32.363382Z","shell.execute_reply":"2025-12-02T14:22:38.184940Z"}},"outputs":[{"name":"stdout","text":"Found 70295 files belonging to 38 classes.\nUsing 56236 files for training.\nFound 17572 files belonging to 38 classes.\nUsing 3514 files for validation.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Define Models\ndef create_model(base_model):\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Initialize models\nmodels = {\n    'VGG16': create_model(VGG16(weights='imagenet', include_top=False, input_shape=image_size + (3,))),\n    'VGG19': create_model(VGG19(weights='imagenet', include_top=False, input_shape=image_size + (3,))),\n    'InceptionV3': create_model(InceptionV3(weights='imagenet', include_top=False, input_shape=image_size + (3,))),\n    'Xception': create_model(Xception(weights='imagenet', include_top=False, input_shape=image_size + (3,))),\n    'ResNet50': create_model(ResNet50(weights='imagenet', include_top=False, input_shape=image_size + (3,))),\n    'DenseNet121': create_model(DenseNet121(weights='imagenet', include_top=False, input_shape=image_size + (3,)))\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:23:41.150604Z","iopub.execute_input":"2025-12-02T14:23:41.150890Z","iopub.status.idle":"2025-12-02T14:23:49.045076Z","shell.execute_reply.started":"2025-12-02T14:23:41.150870Z","shell.execute_reply":"2025-12-02T14:23:49.044486Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\n\n# Train Models\nhistory = {}\nepochs = 10\n\nfor model_name, model in models.items():\n    print(f\"Training {model_name}...\")\n    history[model_name] = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=epochs\n    )\n    model.save(f\"{model_name}_plant_disease_model.h5\")\n    print(f\"{model_name} training completed and model saved.\")\n    \n    # Get predictions\n    y_pred = model.predict(val_dataset)\n    \n    # Extract true labels from the dataset\n    y_true = []\n    for image_batch, label_batch in val_dataset:\n        y_true.append(label_batch)\n    \n    # Concatenate all batches into a single array\n    y_true = tf.concat(y_true, axis=0).numpy()\n    \n    # Save predictions with the model name\n    np.save(f\"{model_name}_y_pred.npy\", y_pred)\n    np.save(f\"{model_name}_y_true.npy\", y_true)\n    print(f'{model_name} predictions saved')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T14:27:47.706080Z","iopub.execute_input":"2025-12-02T14:27:47.706908Z"}},"outputs":[{"name":"stdout","text":"Training VGG16...\nEpoch 1/10\n\u001b[1m   5/1758\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 38ms/step - accuracy: 0.0254 - loss: 3.7533    ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764685674.898314     139 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1758/1758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 74ms/step - accuracy: 0.4615 - loss: 2.4577 - val_accuracy: 0.6357 - val_loss: 1.6177\nEpoch 2/10\n\u001b[1m1758/1758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 45ms/step - accuracy: 0.6774 - loss: 1.3318 - val_accuracy: 0.7057 - val_loss: 1.0996\nEpoch 3/10\n\u001b[1m1758/1758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 46ms/step - accuracy: 0.7331 - loss: 1.0025 - val_accuracy: 0.7439 - val_loss: 0.8972\nEpoch 4/10\n\u001b[1m1758/1758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 45ms/step - accuracy: 0.7622 - loss: 0.8494 - val_accuracy: 0.7752 - val_loss: 0.7825\nEpoch 5/10\n\u001b[1m1758/1758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 45ms/step - accuracy: 0.7831 - loss: 0.7540 - val_accuracy: 0.7894 - val_loss: 0.7068\nEpoch 6/10\n\u001b[1m 229/1758\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 43ms/step - accuracy: 0.7903 - loss: 0.7345","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Generate Model Comparison Table\nimport numpy as np\nimport pandas as pd\n\nmodels = [\"VGG16\", \"VGG19\", \"InceptionV3\", \"Xception\", \"ResNet50\", \"DenseNet121\"]\nresults = []\n\nfor name in models:\n    y_pred = np.load(f\"{name}_y_pred.npy\")\n    y_true = np.load(f\"{name}_y_true.npy\")\n    \n    # Convert predictions and true labels from one-hot to class indices\n    y_pred_labels = y_pred.argmax(axis=1)\n    y_true_labels = y_true.argmax(axis=1)  # Add this line!\n    \n    accuracy = np.mean(y_pred_labels == y_true_labels)\n    results.append({\n        'Model': name,\n        'Accuracy': accuracy\n    })\n\ncomparison_df = pd.DataFrame(results)\nprint(comparison_df)\n\n# Generate Classification Reports\nfrom sklearn.metrics import classification_report\n\nfor name in models:\n    y_pred = np.load(f\"{name}_y_pred.npy\")\n    y_true = np.load(f\"{name}_y_true.npy\")\n    \n    # Convert both predictions and true labels from one-hot to class indices\n    y_pred_labels = y_pred.argmax(axis=1)\n    y_true_labels = y_true.argmax(axis=1)  # Add this line!\n    \n    print(f\"\\n===== {name} =====\")\n    print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}