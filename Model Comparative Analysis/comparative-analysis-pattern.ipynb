{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Classification - Improved Model Comparative Analysis\n",
    "## Optimized for >98.5% Accuracy\n",
    "\n",
    "### Key Improvements:\n",
    "1. **Larger Image Size (224x224)** - Better feature extraction\n",
    "2. **Enhanced Architecture** - Deeper dense layers with dropout\n",
    "3. **Fine-tuning** - Unfreeze top layers for better adaptation\n",
    "4. **More Epochs (30)** - Better convergence\n",
    "5. **Learning Rate Scheduling** - Adaptive learning\n",
    "6. **Early Stopping** - Prevent overfitting\n",
    "7. **Model Checkpointing** - Save best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U 'tensorflow[and-cuda]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50, DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enable mixed precision for faster training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
    "valid = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Larger image size for better feature extraction\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Training dataset - use the entire train folder\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train,\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation dataset - use the entire valid folder (NO validation_split!)\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid,\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False  # Don't shuffle validation data\n",
    ")\n",
    "\n",
    "# SAVE class_names BEFORE applying transformations\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Image size: {image_size}\")\n",
    "\n",
    "# IMPROVED: Enhanced data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Apply augmentation and prefetching to training data\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Apply normalization and prefetching to validation data\n",
    "normalization = tf.keras.layers.Rescaling(1./255)\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda x, y: (normalization(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Enhanced model architecture with deeper layers and dropout\n",
    "def create_model(base_model, model_name):\n",
    "    \"\"\"\n",
    "    Create an improved model with:\n",
    "    - Deeper dense layers\n",
    "    - Dropout for regularization\n",
    "    - BatchNormalization for stability\n",
    "    \"\"\"\n",
    "    # Initially freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # IMPROVED: Deeper architecture with more neurons\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Output layer with float32 for numerical stability\n",
    "    predictions = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # IMPROVED: Higher initial learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),  # Increased from 0.0001\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        jit_compile=True\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to fine-tune model\n",
    "def fine_tune_model(model, base_model, num_layers_to_unfreeze=20):\n",
    "    \"\"\"\n",
    "    Fine-tune the model by unfreezing top layers of base model\n",
    "    \"\"\"\n",
    "    # Unfreeze the base model\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze all layers except the last num_layers_to_unfreeze\n",
    "    for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompile with lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),  # Lower LR for fine-tuning\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models with proper input shapes\n",
    "# Note: InceptionV3 and Xception require minimum 75x75, but 299x299 is optimal\n",
    "# For consistency, we use 224x224 for all models\n",
    "\n",
    "base_models = {\n",
    "    'VGG16': VGG16(weights='imagenet', include_top=False, input_shape=image_size + (3,)),\n",
    "    'VGG19': VGG19(weights='imagenet', include_top=False, input_shape=image_size + (3,)),\n",
    "    'InceptionV3': InceptionV3(weights='imagenet', include_top=False, input_shape=image_size + (3,)),\n",
    "    'Xception': Xception(weights='imagenet', include_top=False, input_shape=image_size + (3,)),\n",
    "    'ResNet50': ResNet50(weights='imagenet', include_top=False, input_shape=image_size + (3,)),\n",
    "    'DenseNet121': DenseNet121(weights='imagenet', include_top=False, input_shape=image_size + (3,))\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for name, base_model in base_models.items():\n",
    "    models[name] = create_model(base_model, name)\n",
    "    print(f\"{name} model created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Define callbacks for better training\n",
    "def get_callbacks(model_name):\n",
    "    \"\"\"\n",
    "    Create callbacks for training:\n",
    "    - EarlyStopping: Stop when validation accuracy plateaus\n",
    "    - ReduceLROnPlateau: Reduce learning rate when stuck\n",
    "    - ModelCheckpoint: Save best model weights\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        # Stop training if val_accuracy doesn't improve for 5 epochs\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate if val_loss doesn't improve for 3 epochs\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Save best model weights\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'{model_name}_best_weights.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Two-stage training process\n",
    "history = {}\n",
    "initial_epochs = 15  # Initial training with frozen base\n",
    "fine_tune_epochs = 15  # Fine-tuning with unfrozen layers\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING STRATEGY:\")\n",
    "print(f\"Stage 1: Initial training for {initial_epochs} epochs (base model frozen)\")\n",
    "print(f\"Stage 2: Fine-tuning for {fine_tune_epochs} epochs (top layers unfrozen)\")\n",
    "print(f\"Total epochs: {total_epochs}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # STAGE 1: Initial Training\n",
    "    print(f\"\\n[STAGE 1] Initial training with frozen base model...\")\n",
    "    history_stage1 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=initial_epochs,\n",
    "        callbacks=get_callbacks(f\"{model_name}_stage1\")\n",
    "    )\n",
    "    \n",
    "    # STAGE 2: Fine-tuning\n",
    "    print(f\"\\n[STAGE 2] Fine-tuning with unfrozen top layers...\")\n",
    "    model = fine_tune_model(model, base_models[model_name], num_layers_to_unfreeze=20)\n",
    "    \n",
    "    history_stage2 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=get_callbacks(f\"{model_name}_stage2\")\n",
    "    )\n",
    "    \n",
    "    # Combine histories\n",
    "    history[model_name] = {\n",
    "        'stage1': history_stage1,\n",
    "        'stage2': history_stage2\n",
    "    }\n",
    "    \n",
    "    # Save final model\n",
    "    model.save(f\"{model_name}_plant_disease_model_improved.h5\")\n",
    "    print(f\"\\n{model_name} training completed and model saved.\")\n",
    "    \n",
    "    # Get predictions\n",
    "    print(f\"\\nGenerating predictions for {model_name}...\")\n",
    "    y_pred = model.predict(val_dataset)\n",
    "    \n",
    "    # Extract true labels from the dataset\n",
    "    y_true = []\n",
    "    for image_batch, label_batch in val_dataset:\n",
    "        y_true.append(label_batch)\n",
    "    \n",
    "    # Concatenate all batches into a single array\n",
    "    y_true = tf.concat(y_true, axis=0).numpy()\n",
    "    \n",
    "    # Save predictions with the model name\n",
    "    np.save(f\"{model_name}_y_pred_improved.npy\", y_pred)\n",
    "    np.save(f\"{model_name}_y_true_improved.npy\", y_true)\n",
    "    print(f'{model_name} predictions saved')\n",
    "    \n",
    "    # Calculate and display final accuracy\n",
    "    y_pred_labels = y_pred.argmax(axis=1)\n",
    "    y_true_labels = y_true.argmax(axis=1)\n",
    "    final_accuracy = np.mean(y_pred_labels == y_true_labels)\n",
    "    print(f\"\\n{model_name} FINAL VALIDATION ACCURACY: {final_accuracy*100:.2f}%\")\n",
    "    \n",
    "    if final_accuracy >= 0.985:\n",
    "        print(f\"✓ {model_name} achieved >=98.5% accuracy!\")\n",
    "    else:\n",
    "        print(f\"✗ {model_name} did not reach 98.5% accuracy (got {final_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL MODELS TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL TEST EVALUATION (Run this AFTER all training is complete)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL TEST EVALUATION ON UNSEEN DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load test dataset\n",
    "test = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/test'\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test,\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False  # Important: don't shuffle test data\n",
    ")\n",
    "\n",
    "# Apply only normalization (NO augmentation for test!)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x, y: (normalization(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Evaluate each model on test set\n",
    "test_results = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Testing {model_name} on unseen test data...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(f\"{model_name}_plant_disease_model_improved.h5\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset, verbose=1)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_test_pred = model.predict(test_dataset)\n",
    "    \n",
    "    # Extract true labels\n",
    "    y_test_true = []\n",
    "    for image_batch, label_batch in test_dataset:\n",
    "        y_test_true.append(label_batch)\n",
    "    y_test_true = tf.concat(y_test_true, axis=0).numpy()\n",
    "    \n",
    "    # Convert to class labels\n",
    "    y_test_pred_labels = y_test_pred.argmax(axis=1)\n",
    "    y_test_true_labels = y_test_true.argmax(axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    \n",
    "    precision = precision_score(y_test_true_labels, y_test_pred_labels, average='weighted')\n",
    "    recall = recall_score(y_test_true_labels, y_test_pred_labels, average='weighted')\n",
    "    f1 = f1_score(y_test_true_labels, y_test_pred_labels, average='weighted')\n",
    "    \n",
    "    test_results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy (%)': test_accuracy * 100,\n",
    "        'Precision (%)': precision * 100,\n",
    "        'Recall (%)': recall * 100,\n",
    "        'F1-Score (%)': f1 * 100,\n",
    "        'Test Loss': test_loss\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name} Test Results:\")\n",
    "    print(f\"  Accuracy:  {test_accuracy*100:.2f}%\")\n",
    "    print(f\"  Precision: {precision*100:.2f}%\")\n",
    "    print(f\"  Recall:    {recall*100:.2f}%\")\n",
    "    print(f\"  F1-Score:  {f1*100:.2f}%\")\n",
    "    print(f\"  Loss:      {test_loss:.4f}\")\n",
    "\n",
    "# Create comparison table\n",
    "test_comparison_df = pd.DataFrame(test_results)\n",
    "test_comparison_df = test_comparison_df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL TEST RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + test_comparison_df.to_string(index=False))\n",
    "\n",
    "# Save test results\n",
    "test_comparison_df.to_csv('test_results_comparison.csv', index=False)\n",
    "print(\"\\n✓ Test results saved to 'test_results_comparison.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model Comparison Table\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "model_names = [\"VGG16\", \"VGG19\", \"InceptionV3\", \"Xception\", \"ResNet50\", \"DenseNet121\"]\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name in model_names:\n",
    "    y_pred = np.load(f\"{name}_y_pred_improved.npy\")\n",
    "    y_true = np.load(f\"{name}_y_true_improved.npy\")\n",
    "    \n",
    "    # Convert predictions and true labels from one-hot to class indices\n",
    "    y_pred_labels = y_pred.argmax(axis=1)\n",
    "    y_true_labels = y_true.argmax(axis=1)\n",
    "    \n",
    "    accuracy = np.mean(y_pred_labels == y_true_labels)\n",
    "    \n",
    "    # Calculate top-5 accuracy\n",
    "    top5_pred = np.argsort(y_pred, axis=1)[:, -5:]\n",
    "    top5_accuracy = np.mean([y_true_labels[i] in top5_pred[i] for i in range(len(y_true_labels))])\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy (%)': accuracy * 100,\n",
    "        'Top-5 Accuracy (%)': top5_accuracy * 100,\n",
    "        'Meets Target (>98.5%)': '✓' if accuracy > 0.985 else '✗'\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df = comparison_df.sort_values('Accuracy (%)', ascending=False)\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Count how many models achieved >98.5%\n",
    "models_above_target = comparison_df[comparison_df['Meets Target (>98.5%)'] == '✓'].shape[0]\n",
    "print(f\"\\nModels achieving >98.5% accuracy: {models_above_target}/{len(model_names)}\")\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv('model_comparison_improved.csv', index=False)\n",
    "print(\"\\nComparison table saved to 'model_comparison_improved.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification reports for each model\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name in model_names:\n",
    "    y_pred = np.load(f\"{name}_y_pred_improved.npy\")\n",
    "    y_true = np.load(f\"{name}_y_true_improved.npy\")\n",
    "    \n",
    "    # Convert both predictions and true labels from one-hot to class indices\n",
    "    y_pred_labels = y_pred.argmax(axis=1)\n",
    "    y_true_labels = y_true.argmax(axis=1)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{name} - Classification Report\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open(f\"{name}_classification_report_improved.txt\", 'w') as f:\n",
    "        f.write(f\"{name} - Classification Report\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"Report saved to '{name}_classification_report_improved.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history for best performing model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the best model based on accuracy\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"Visualizing training history for best model: {best_model_name}\")\n",
    "\n",
    "if best_model_name in history:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Combine stage 1 and stage 2 histories\n",
    "    stage1 = history[best_model_name]['stage1']\n",
    "    stage2 = history[best_model_name]['stage2']\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[0].plot(stage1.history['accuracy'] + stage2.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0].plot(stage1.history['val_accuracy'] + stage2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0].axvline(x=len(stage1.history['accuracy']), color='r', linestyle='--', label='Fine-tuning starts')\n",
    "    axes[0].axhline(y=0.985, color='g', linestyle='--', label='Target (98.5%)')\n",
    "    axes[0].set_title(f'{best_model_name} - Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    axes[1].plot(stage1.history['loss'] + stage2.history['loss'], label='Training Loss')\n",
    "    axes[1].plot(stage1.history['val_loss'] + stage2.history['val_loss'], label='Validation Loss')\n",
    "    axes[1].axvline(x=len(stage1.history['loss']), color='r', linestyle='--', label='Fine-tuning starts')\n",
    "    axes[1].set_title(f'{best_model_name} - Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{best_model_name}_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Training history plot saved to '{best_model_name}_training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal models trained: {len(model_names)}\")\n",
    "print(f\"Models achieving >98.5% accuracy: {models_above_target}\")\n",
    "print(f\"\\nBest performing model: {comparison_df.iloc[0]['Model']}\")\n",
    "print(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy (%)']:.2f}%\")\n",
    "print(\"\\nKey improvements implemented:\")\n",
    "print(\"  ✓ Increased image size to 224x224\")\n",
    "print(\"  ✓ Enhanced architecture with deeper layers and dropout\")\n",
    "print(\"  ✓ Two-stage training with fine-tuning\")\n",
    "print(\"  ✓ Learning rate scheduling\")\n",
    "print(\"  ✓ Early stopping and model checkpointing\")\n",
    "print(\"  ✓ Enhanced data augmentation\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "isGpuEnabled": true,
   "isInternetEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
