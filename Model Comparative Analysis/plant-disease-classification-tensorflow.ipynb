{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåø PLANT DISEASE CLASSIFICATION USING TENSORFLOW/KERAS üåø"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏èDISCLAIMER: This notebook is a TensorFlow/Keras implementation of the original PyTorch notebook. It provides the same functionality using TensorFlow and Keras APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the dataset üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is created using offline augmentation from the original dataset. The original PlantVillage Dataset can be found [here](https://github.com/spMohanty/PlantVillage-Dataset).This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose.\n",
    "\n",
    "Note: This description is given in the dataset itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our goal üéØ\n",
    "Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's get started...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß≠ Exploring the data üß≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('___')[0] not in plants:\n",
    "        plants.append(plant.split('___')[0])\n",
    "    if plant.split('___')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(38)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üç≥ Data Preparation for training üç≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data generators with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë∑ Building the model architecture üë∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We are going to use **ResNet-like architecture**, which have been one of the major breakthrough in computer vision since they were introduced in 2015.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Block implementation in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, pool=False):\n",
    "    \"\"\"Convolutional block with BatchNormalization\"\"\"\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if pool:\n",
    "        x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(x, filters):\n",
    "    \"\"\"Residual block with skip connection\"\"\"\n",
    "    res = x\n",
    "    x = conv_block(x, filters)\n",
    "    x = conv_block(x, filters)\n",
    "    x = layers.Add()([x, res])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë∑ Defining the final architecture of our model üë∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet9(input_shape=(256, 256, 3), num_classes=38):\n",
    "    \"\"\"Create ResNet9 architecture using Keras Functional API\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = conv_block(inputs, 64)\n",
    "    x = conv_block(x, 128, pool=True)  # 128 x 64 x 64\n",
    "    \n",
    "    # First residual block\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    # More convolutions\n",
    "    x = conv_block(x, 256, pool=True)  # 256 x 16 x 16\n",
    "    x = conv_block(x, 512, pool=True)  # 512 x 4 x 4\n",
    "    \n",
    "    # Second residual block\n",
    "    x = residual_block(x, 512)\n",
    "    \n",
    "    # Classifier\n",
    "    x = layers.GlobalMaxPooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name='ResNet9')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = create_resnet9(num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèãÔ∏è Training the model üèãÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up callbacks and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "INITIAL_LR = 0.01\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Visualizing Training Results üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Model Evaluation üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(valid_generator)\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Saving the Model üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('plant_disease_model_final.keras')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÆ Making Predictions üîÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease(image_path, model, class_names):\n",
    "    \"\"\"Predict disease from an image\"\"\"\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2%}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Get class names\n",
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to build a plant disease classification model using TensorFlow/Keras with a ResNet-inspired architecture. The model achieves high accuracy in classifying 38 different plant disease classes.\n",
    "\n",
    "Key features:\n",
    "- ResNet-like architecture with residual connections\n",
    "- Data augmentation for better generalization\n",
    "- Learning rate scheduling and early stopping\n",
    "- Model checkpointing to save the best model\n",
    "\n",
    "The TensorFlow/Keras implementation provides similar functionality to the PyTorch version while leveraging the high-level Keras API for easier model building and training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
