{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":182633,"datasetId":78313,"databundleVersionId":193494,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U 'tensorflow[and-cuda]'","metadata":{"id":"Q1SWtHbKmRTs"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import Required Libraries\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50, DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport os\nimport numpy as np\nimport pandas as pd\nimport gc\nfrom tensorflow.keras import backend as K\n\n# Enable mixed precision for faster training\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')\n\nprint(\"TensorFlow version:\", tf.__version__)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJLG7VcnmRTt","outputId":"b3519b06-5eee-4c0e-943c-e65e192ddf83","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:15:09.423461Z","iopub.execute_input":"2025-12-04T14:15:09.423709Z","iopub.status.idle":"2025-12-04T14:15:26.033259Z","shell.execute_reply.started":"2025-12-04T14:15:09.423691Z","shell.execute_reply":"2025-12-04T14:15:26.032591Z"}},"outputs":[{"name":"stderr","text":"2025-12-04 14:15:10.855694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764857711.037638      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764857711.093040      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"TensorFlow version: 2.18.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCmICxH4mjgx","outputId":"48c4d947-97a2-4ede-e502-ba009307eac0","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:15:32.406626Z","iopub.execute_input":"2025-12-04T14:15:32.407603Z","iopub.status.idle":"2025-12-04T14:15:32.708736Z","shell.execute_reply.started":"2025-12-04T14:15:32.407574Z","shell.execute_reply":"2025-12-04T14:15:32.708070Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/new-plant-diseases-dataset\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Dataset paths\n# For Kaggle kernel:\ntrain = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\nvalid = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n\n# train = \"C:\\\\Users\\\\junu\\\\.cache\\\\kagglehub\\\\datasets\\\\vipoooool\\\\new-plant-diseases-dataset\\\\versions\\\\2\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\"\n# valid = \"C:\\\\Users\\\\junu\\\\.cache\\\\kagglehub\\\\datasets\\\\vipoooool\\\\new-plant-diseases-dataset\\\\versions\\\\2\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\valid\"","metadata":{"id":"Y-DmJZw5mRTu","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:15:36.531280Z","iopub.execute_input":"2025-12-04T14:15:36.531569Z","iopub.status.idle":"2025-12-04T14:15:36.535463Z","shell.execute_reply.started":"2025-12-04T14:15:36.531547Z","shell.execute_reply":"2025-12-04T14:15:36.534768Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Configuration\nimage_size = (256, 256)  \nbatch_size = 32          \n\nprint(f\"Image size: {image_size}\")\nprint(f\"Batch size: {batch_size}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKbJD82tmRTv","outputId":"93415f07-8c8f-4e44-e8a7-75046ed4b7ec","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:15:39.884569Z","iopub.execute_input":"2025-12-04T14:15:39.885041Z","iopub.status.idle":"2025-12-04T14:15:39.889231Z","shell.execute_reply.started":"2025-12-04T14:15:39.885017Z","shell.execute_reply":"2025-12-04T14:15:39.888535Z"}},"outputs":[{"name":"stdout","text":"Image size: (299, 299)\nBatch size: 64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Create datasets WITHOUT caching\ndef create_datasets():\n    \"\"\"\n    Create training and validation datasets WITHOUT caching.\n    Data will be loaded fresh from disk each epoch.\n    Uses minimal memory but slower training.\n    \"\"\"\n    # Training dataset\n    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        train,\n        seed=123,\n        image_size=image_size,\n        batch_size=batch_size,\n        label_mode='categorical',\n        shuffle=True\n    )\n\n    # Validation dataset\n    val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        valid,\n        seed=123,\n        image_size=image_size,\n        batch_size=batch_size,\n        label_mode='categorical',\n        shuffle=False\n    )\n\n    # Save class names\n    class_names = train_dataset.class_names\n    num_classes = len(class_names)\n\n    print(f\"Number of classes: {num_classes}\")\n\n    total_batches = train_dataset.cardinality().numpy()\n\n    train_dataset = train_dataset.shuffle(\n        buffer_size=100,\n        reshuffle_each_iteration=True\n    )\n\n    portion = 0.01\n    train_dataset = train_dataset.take(int(total_batches * portion))\n\n    data_augmentation = tf.keras.Sequential([\n        tf.keras.layers.Rescaling(1./255),\n        tf.keras.layers.RandomFlip(\"horizontal\"),\n        tf.keras.layers.RandomFlip(\"vertical\"),\n        tf.keras.layers.RandomRotation(0.2),\n        tf.keras.layers.RandomZoom(0.2),\n        tf.keras.layers.RandomContrast(0.2),\n    ])\n\n    normalization = tf.keras.layers.Rescaling(1./255)\n\n    train_dataset = train_dataset.map(\n        lambda x, y: (data_augmentation(x, training=True), y),\n        num_parallel_calls=tf.data.AUTOTUNE\n    ).prefetch(tf.data.AUTOTUNE)\n\n    val_dataset = val_dataset.map(\n        lambda x, y: (normalization(x), y),\n        num_parallel_calls=tf.data.AUTOTUNE\n    ).prefetch(tf.data.AUTOTUNE)\n\n    return train_dataset, val_dataset, class_names, num_classes\n\nprint(\"Creating datasets...\")\ntrain_dataset, val_dataset, class_names, num_classes = create_datasets()\nprint(\"\\n✓ Datasets created successfully!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sy3p_eWQmRTv","outputId":"b5e04546-0c83-4edc-a0ad-c16be3736d24","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:15:43.600136Z","iopub.execute_input":"2025-12-04T14:15:43.600414Z","iopub.status.idle":"2025-12-04T14:16:06.719915Z","shell.execute_reply.started":"2025-12-04T14:15:43.600393Z","shell.execute_reply":"2025-12-04T14:16:06.719285Z"}},"outputs":[{"name":"stdout","text":"Creating datasets...\nFound 70295 files belonging to 38 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764857762.504696      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Found 17572 files belonging to 38 classes.\nNumber of classes: 38\n\n✓ Datasets created successfully!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\ndef create_model(base_model_class, model_name, num_classes):\n\n    base_model = base_model_class(\n        weights='imagenet',\n        include_top=False,\n        input_shape=image_size + (3,)\n    )\n\n    base_model.trainable = False\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.2)(x)\n\n    predictions = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy'],\n        jit_compile=True\n    )\n\n    return model, base_model\n\ndef fine_tune_model(model, base_model, num_layers_to_unfreeze=20):\n    \"\"\"\n    Fine-tune the model by unfreezing top layers.\n    \"\"\"\n    base_model.trainable = True\n\n    for layer in base_model.layers[:-num_layers_to_unfreeze]:\n        layer.trainable = False\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\ndef get_callbacks(model_name):\n    \"\"\"\n    Create callbacks for training.\n    \"\"\"\n    callbacks = [\n        EarlyStopping(\n            monitor='val_accuracy',\n            patience=5,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-7,\n            verbose=1\n        ),\n        ModelCheckpoint(\n            filepath=f'{model_name}_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        )\n    ]\n    return callbacks\n\ndef train_single_model(model_name, base_model_class):\n    \"\"\"\n    Train a single model with two-stage training.\n    \"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"TRAINING {model_name}\")\n    print(f\"{'='*80}\")\n\n    print(f\"\\nCreating {model_name} model...\")\n    model, base_model = create_model(base_model_class, model_name, num_classes)\n    print(f\"✓ {model_name} model created\")\n\n    print(f\"\\n[STAGE 1] Initial training with frozen base model...\")\n    initial_epochs = 10\n\n    history_stage1 = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=initial_epochs,\n        callbacks=get_callbacks(f\"{model_name}_stage1\")\n    )\n\n    print(f\"\\n[STAGE 2] Fine-tuning with unfrozen top layers...\")\n    model = fine_tune_model(model, base_model, num_layers_to_unfreeze=20)\n    fine_tune_epochs = 10\n\n    history_stage2 = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=fine_tune_epochs,\n        callbacks=get_callbacks(f\"{model_name}_stage2\")\n    )\n\n    model.save(f\"{model_name}_plant_disease_model.h5\")\n    print(f\"\\n✓ {model_name} model saved\")\n\n    print(f\"\\nGenerating predictions for {model_name}...\")\n    y_pred = model.predict(val_dataset)\n\n    y_true = []\n    for image_batch, label_batch in val_dataset:\n        y_true.append(label_batch)\n    y_true = tf.concat(y_true, axis=0).numpy()\n\n    np.save(f\"{model_name}_y_pred.npy\", y_pred)\n    np.save(f\"{model_name}_y_true.npy\", y_true)\n    print(f\"✓ {model_name} predictions saved\")\n\n    # Calculate accuracy\n    y_pred_labels = y_pred.argmax(axis=1)\n    y_true_labels = y_true.argmax(axis=1)\n    accuracy = np.mean(y_pred_labels == y_true_labels)\n\n    print(f\"\\n{model_name} FINAL VALIDATION ACCURACY: {accuracy*100:.2f}%\")\n\n    if accuracy >= 0.985:\n        print(f\"✓ {model_name} achieved >=98.5% accuracy!\")\n    else:\n        print(f\"✗ {model_name} did not reach 98.5% accuracy (got {accuracy*100:.2f}%)\")\n\n    # Clear memory before next model\n    del model, base_model\n\n    return accuracy\n\nprint(\"✓ Helper functions defined\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpKKWDDOmRTw","outputId":"1c38b191-7f6c-45be-9210-c97102b02f0f","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:16:30.104286Z","iopub.execute_input":"2025-12-04T14:16:30.104590Z","iopub.status.idle":"2025-12-04T14:16:30.118171Z","shell.execute_reply.started":"2025-12-04T14:16:30.104568Z","shell.execute_reply":"2025-12-04T14:16:30.117253Z"}},"outputs":[{"name":"stdout","text":"✓ Helper functions defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"---\n## Model Training Cells\n**Run each cell below to train that specific model. Skip any cell to exclude that model from training.**\n\n---","metadata":{"id":"-XAHNx9OmRTw"}},{"cell_type":"code","source":"# Train VGG16\ntry:\n    vgg16_accuracy = train_single_model('VGG16', VGG16)\nexcept Exception as e:\n    print(f\"❌ Error training VGG16: {str(e)}\")","metadata":{"id":"KXcKwddjmRTx"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train VGG19\ntry:\n    vgg19_accuracy = train_single_model('VGG19', VGG19)\nexcept Exception as e:\n    print(f\"❌ Error training VGG19: {str(e)}\")\n","metadata":{"id":"qJQDASq7mRTy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train InceptionV3\ntry:\n    inceptionv3_accuracy = train_single_model('InceptionV3', InceptionV3)\nexcept Exception as e:\n    print(f\"❌ Error training InceptionV3: {str(e)}\")\n","metadata":{"id":"aN6aaNBumRTz"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train Xception\ntry:\n    xception_accuracy = train_single_model('Xception', Xception)\nexcept Exception as e:\n    print(f\"❌ Error training Xception: {str(e)}\")\n","metadata":{"id":"n3p8_BeimRTz"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train ResNet50\ntry:\n    resnet50_accuracy = train_single_model('ResNet50', ResNet50)\nexcept Exception as e:\n    print(f\"❌ Error training ResNet50: {str(e)}\")\n","metadata":{"id":"_m6xoV2-mRTz","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:16:38.951537Z","iopub.execute_input":"2025-12-04T14:16:38.951844Z","iopub.status.idle":"2025-12-04T14:31:37.371119Z","shell.execute_reply.started":"2025-12-04T14:16:38.951821Z","shell.execute_reply":"2025-12-04T14:31:37.370398Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTRAINING ResNet50\n================================================================================\n\nCreating ResNet50 model...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n✓ ResNet50 model created\n\n[STAGE 1] Initial training with frozen base model...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1764857826.969318     115 service.cc:148] XLA service 0x7d81580029d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1764857826.970180     115 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1764857829.598358     115 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:49\u001b[0m 39s/step - accuracy: 0.0312 - loss: 4.2709","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764857840.148884     115 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.0281 - loss: 4.3379\nEpoch 1: val_accuracy improved from -inf to 0.02760, saving model to ResNet50_stage1_best.weights.h5\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 6s/step - accuracy: 0.0280 - loss: 4.3392 - val_accuracy: 0.0276 - val_loss: 3.7424 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655ms/step - accuracy: 0.0277 - loss: 4.1151\nEpoch 2: val_accuracy did not improve from 0.02760\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0284 - loss: 4.1147 - val_accuracy: 0.0276 - val_loss: 3.8241 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.0705 - loss: 3.8106\nEpoch 3: val_accuracy improved from 0.02760 to 0.02766, saving model to ResNet50_stage1_best.weights.h5\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0705 - loss: 3.8094 - val_accuracy: 0.0277 - val_loss: 3.9949 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - accuracy: 0.0629 - loss: 3.7391\nEpoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 4: val_accuracy did not improve from 0.02766\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0636 - loss: 3.7372 - val_accuracy: 0.0274 - val_loss: 4.0102 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.0596 - loss: 3.6478\nEpoch 5: val_accuracy did not improve from 0.02766\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0614 - loss: 3.6420 - val_accuracy: 0.0274 - val_loss: 4.0354 - learning_rate: 5.0000e-04\nEpoch 6/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - accuracy: 0.1047 - loss: 3.5380\nEpoch 6: val_accuracy did not improve from 0.02766\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.1052 - loss: 3.5403 - val_accuracy: 0.0274 - val_loss: 3.9830 - learning_rate: 5.0000e-04\nEpoch 7/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.0958 - loss: 3.5611\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 7: val_accuracy did not improve from 0.02766\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0978 - loss: 3.5502 - val_accuracy: 0.0273 - val_loss: 3.9407 - learning_rate: 5.0000e-04\nEpoch 8/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - accuracy: 0.1189 - loss: 3.4679\nEpoch 8: val_accuracy did not improve from 0.02766\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.1190 - loss: 3.4641 - val_accuracy: 0.0274 - val_loss: 3.9166 - learning_rate: 2.5000e-04\nEpoch 8: early stopping\nRestoring model weights from the end of the best epoch: 3.\n\n[STAGE 2] Fine-tuning with unfrozen top layers...\nEpoch 1/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.0589 - loss: 3.9221\nEpoch 1: val_accuracy improved from -inf to 0.04058, saving model to ResNet50_stage2_best.weights.h5\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.0591 - loss: 3.9190 - val_accuracy: 0.0406 - val_loss: 3.9752 - learning_rate: 1.0000e-04\nEpoch 2/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.0553 - loss: 3.9244\nEpoch 2: val_accuracy did not improve from 0.04058\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0562 - loss: 3.9117 - val_accuracy: 0.0252 - val_loss: 3.9642 - learning_rate: 1.0000e-04\nEpoch 3/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651ms/step - accuracy: 0.0602 - loss: 3.8245\nEpoch 3: val_accuracy did not improve from 0.04058\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0600 - loss: 3.8295 - val_accuracy: 0.0265 - val_loss: 3.9432 - learning_rate: 1.0000e-04\nEpoch 4/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.0820 - loss: 3.7469\nEpoch 4: val_accuracy did not improve from 0.04058\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0808 - loss: 3.7474 - val_accuracy: 0.0241 - val_loss: 3.8979 - learning_rate: 1.0000e-04\nEpoch 5/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step - accuracy: 0.0733 - loss: 3.6682\nEpoch 5: val_accuracy did not improve from 0.04058\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0736 - loss: 3.6685 - val_accuracy: 0.0256 - val_loss: 3.8395 - learning_rate: 1.0000e-04\nEpoch 6/10\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - accuracy: 0.0837 - loss: 3.6558\nEpoch 6: val_accuracy did not improve from 0.04058\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.0833 - loss: 3.6582 - val_accuracy: 0.0260 - val_loss: 3.7786 - learning_rate: 1.0000e-04\nEpoch 6: early stopping\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\n✓ ResNet50 model saved\n\nGenerating predictions for ResNet50...\n\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 162ms/step\n✓ ResNet50 predictions saved\n\nResNet50 FINAL VALIDATION ACCURACY: 4.06%\n✗ ResNet50 did not reach 98.5% accuracy (got 4.06%)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Train DenseNet121\ntry:\n    densenet121_accuracy = train_single_model('DenseNet121', DenseNet121)\nexcept Exception as e:\n    print(f\"❌ Error training DenseNet121: {str(e)}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tk4KdR7wmRT0","outputId":"d69c7713-f01e-4844-d98d-c33192a68297","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:54:59.183065Z","iopub.execute_input":"2025-12-04T13:54:59.183827Z","execution_failed":"2025-12-04T13:56:01.121Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTRAINING DenseNet121\n================================================================================\n\nCreating DenseNet121 model...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n✓ DenseNet121 model created\n\n[STAGE 1] Initial training with frozen base model...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2025-12-04 13:55:49.369125: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 17179869184 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\nW0000 00:00:1764856549.369186     186 device_host_allocator.h:61] could not allocate pinned host memory of size: 17179869184\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"---\n## Results & Comparison\n**Run the cells below after training your models to see the comparison.**\n\n---","metadata":{"id":"IfY9K7i0mRT0"}},{"cell_type":"code","source":"# Generate comparison table\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nprint(\"=\"*80)\nprint(\"MODEL COMPARISON RESULTS\")\nprint(\"=\"*80)\n\n# List of all possible models\nall_models = ['VGG16', 'VGG19', 'InceptionV3', 'Xception', 'ResNet50', 'DenseNet121']\nresults = []\n\nfor model_name in all_models:\n    try:\n        # Load predictions\n        y_pred = np.load(f\"{model_name}_y_pred.npy\")\n        y_true = np.load(f\"{model_name}_y_true.npy\")\n\n        # Convert to class labels\n        y_pred_labels = y_pred.argmax(axis=1)\n        y_true_labels = y_true.argmax(axis=1)\n\n        # Calculate metrics\n        accuracy = np.mean(y_pred_labels == y_true_labels)\n        precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n        recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n        f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n\n        # Top-5 accuracy\n        top5_pred = np.argsort(y_pred, axis=1)[:, -5:]\n        top5_accuracy = np.mean([y_true_labels[i] in top5_pred[i] for i in range(len(y_true_labels))])\n\n        results.append({\n            'Model': model_name,\n            'Accuracy (%)': accuracy * 100,\n            'Precision (%)': precision * 100,\n            'Recall (%)': recall * 100,\n            'F1-Score (%)': f1 * 100,\n            'Top-5 Accuracy (%)': top5_accuracy * 100,\n            'Meets Target (>98.5%)': '✓' if accuracy > 0.985 else '✗'\n        })\n    except FileNotFoundError:\n        print(f\"⚠️  {model_name} was not trained (skipped)\")\n    except Exception as e:\n        print(f\"Warning: Could not load results for {model_name}: {str(e)}\")\n\nif len(results) > 0:\n    # Create DataFrame\n    comparison_df = pd.DataFrame(results)\n    comparison_df = comparison_df.sort_values('Accuracy (%)', ascending=False)\n\n    print(\"\\n\" + comparison_df.to_string(index=False))\n    print(\"\\n\" + \"=\"*80)\n\n    # Count models above target\n    models_above_target = comparison_df[comparison_df['Meets Target (>98.5%)'] == '✓'].shape[0]\n    print(f\"\\nModels achieving >98.5% accuracy: {models_above_target}/{len(results)}\")\n\n    # Save comparison table\n    comparison_df.to_csv('model_comparison_sequential.csv', index=False)\n    print(\"\\n✓ Comparison table saved to 'model_comparison_sequential.csv'\")\nelse:\n    print(\"\\n⚠️  No models were trained. Please run at least one model training cell above.\")","metadata":{"id":"Mv1RLDl2mRT0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize comparison\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nif len(results) > 0:\n    # Set style\n    sns.set_style('whitegrid')\n    plt.figure(figsize=(12, 6))\n\n    # Plot accuracy comparison\n    plt.subplot(1, 2, 1)\n    colors = ['green' if x == '✓' else 'red' for x in comparison_df['Meets Target (>98.5%)']]\n    plt.barh(comparison_df['Model'], comparison_df['Accuracy (%)'], color=colors, alpha=0.7)\n    plt.axvline(x=98.5, color='blue', linestyle='--', label='Target (98.5%)')\n    plt.xlabel('Accuracy (%)')\n    plt.title('Model Accuracy Comparison')\n    plt.legend()\n    plt.tight_layout()\n\n    # Plot metrics comparison\n    plt.subplot(1, 2, 2)\n    metrics_df = comparison_df[['Model', 'Precision (%)', 'Recall (%)', 'F1-Score (%)']].set_index('Model')\n    metrics_df.plot(kind='bar', ax=plt.gca(), width=0.8)\n    plt.ylabel('Score (%)')\n    plt.title('Model Metrics Comparison')\n    plt.xticks(rotation=45, ha='right')\n    plt.legend(loc='lower right')\n    plt.tight_layout()\n\n    plt.savefig('model_comparison_visualization.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    print(\"✓ Visualization saved to 'model_comparison_visualization.png'\")\nelse:\n    print(\"⚠️  No results to visualize. Train at least one model first.\")","metadata":{"id":"mQPFtulemRT0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate detailed classification reports\nfrom sklearn.metrics import classification_report\n\nprint(\"=\"*80)\nprint(\"DETAILED CLASSIFICATION REPORTS\")\nprint(\"=\"*80)\n\nfor model_name in all_models:\n    try:\n        y_pred = np.load(f\"{model_name}_y_pred.npy\")\n        y_true = np.load(f\"{model_name}_y_true.npy\")\n\n        y_pred_labels = y_pred.argmax(axis=1)\n        y_true_labels = y_true.argmax(axis=1)\n\n        print(f\"\\n{'='*80}\")\n        print(f\"{model_name} - Classification Report\")\n        print(f\"{'='*80}\")\n\n        report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n        print(report)\n\n        # Save report\n        with open(f\"{model_name}_classification_report.txt\", 'w') as f:\n            f.write(f\"{model_name} - Classification Report\\n\")\n            f.write(\"=\"*80 + \"\\n\")\n            f.write(report)\n\n        print(f\"✓ Report saved to '{model_name}_classification_report.txt'\")\n    except FileNotFoundError:\n        print(f\"\\n⚠️  {model_name} was not trained (skipped)\")\n    except Exception as e:\n        print(f\"Warning: Could not generate report for {model_name}: {str(e)}\")","metadata":{"id":"m72gSaybmRT1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL SUMMARY\")\nprint(\"=\"*80)\n\nif len(results) > 0:\n    print(f\"\\nTotal models trained: {len(results)}\")\n    print(f\"Models achieving >98.5% accuracy: {models_above_target}\")\n    print(f\"\\nBest performing model: {comparison_df.iloc[0]['Model']}\")\n    print(f\"Best accuracy: {comparison_df.iloc[0]['Accuracy (%)']:.2f}%\")\nelse:\n    print(\"\\n⚠️  No models were trained.\")\n\nprint(\"\\nKey features implemented:\")\nprint(\"  ✓ Sequential training (one model at a time)\")\nprint(\"  ✓ Separate cells for each model (skip any model)\")\nprint(\"  ✓ NO caching (minimal memory usage)\")\nprint(\"  ✓ Memory management between models\")\nprint(\"  ✓ GPU memory growth enabled\")\nprint(\"  ✓ Mixed precision training\")\nprint(\"  ✓ Two-stage training with fine-tuning\")\nprint(\"  ✓ Enhanced data augmentation\")\nprint(\"  ✓ Learning rate scheduling\")\nprint(\"  ✓ Early stopping and model checkpointing\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\"*80)","metadata":{"id":"qM4UZ7PNmRT1"},"outputs":[],"execution_count":null}]}